{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sziraqui/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv3D, ZeroPadding3D, Conv2D, ZeroPadding2D\n",
    "from keras.layers.pooling import MaxPooling3D, MaxPooling2D\n",
    "from keras.layers.core import SpatialDropout3D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras import backend as K\n",
    "from new_attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "input_shape = (109, 109, 5) \n",
    "input_data = Input(shape=input_shape, dtype='float32')\n",
    "\n",
    "conv1 = Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu')(input_data)\n",
    "batch1 = BatchNormalization()(conv1)\n",
    "maxpool1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(batch1)\n",
    "\n",
    "conv2 = Conv2D(filters=256, kernel_size=(3,3), strides=(2,2), activation='relu')(maxpool1)\n",
    "batch2 = BatchNormalization()(conv2)\n",
    "maxpool2 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(batch2)\n",
    "\n",
    "conv3 = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu')(maxpool2)\n",
    "batch3 = TimeDistributed(BatchNormalization())(conv3)  #TimeDistributed?? Come back\n",
    "\n",
    "conv4 = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu')(batch3)\n",
    "batch4 = BatchNormalization()(conv4)\n",
    "\n",
    "conv5 = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu')(batch4)\n",
    "batch5 = BatchNormalization()(conv5)\n",
    "maxpool5 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(batch5)\n",
    "\n",
    "td1 = TimeDistributed(Flatten())(maxpool5)\n",
    "\n",
    "lstm1 = LSTM(256, return_state=True)(td1)\n",
    "\n",
    "#NO NEED OF 6 PAIRS ............... WE HAVE MISUNDERSTOOD .................... NOW OKAY!\n",
    "\n",
    "#DOUBT:- Now another cnn layer? so another input shape? Ridiculous!! We are not making models for each image. \n",
    "# Everything is continuous. Now lstm inputs can be given to another lstm but what about another cnn layer? Heck!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3744ac260744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Check arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Do we have to put in a Dense with Softmax? umm... I don't think so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'output_dim'"
     ]
    }
   ],
   "source": [
    "attention_decoder = AttentionDecoder(...)(lstm1)\n",
    "\n",
    "#Check arguments\n",
    "#Do we have to put in a Dense with Softmax? umm... I don't think so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
